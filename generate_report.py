import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from fpdf import FPDF
import os
import json
import traceback
from datetime import datetime

# Set plot style
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("deep")
plt.rcParams.update({'font.size': 12})

# Define constants for the report
RESULTS_FILE = 'context_aware_hyperparameter_search_results.csv'
OUTPUT_PDF = 'SquareCB_Experiment_Report.pdf'

# Load experiment data
def load_experiment_data():
    """Load the experiment results from CSV file"""
    if not os.path.exists(RESULTS_FILE):
        print(f"Error: Results file '{RESULTS_FILE}' not found.")
        return None
    
    df = pd.read_csv(RESULTS_FILE)
    print(f"Loaded {len(df)} experiment runs from {RESULTS_FILE}")
    return df

# Safe parsing functions for context performance data
def safe_parse_json(json_str):
    """Safely parse a JSON string, handling potential errors"""
    if isinstance(json_str, dict):
        return json_str
    
    try:
        # Try to parse as JSON
        return json.loads(json_str.replace("'", '"'))
    except (json.JSONDecodeError, AttributeError, TypeError):
        try:
            # Fall back to eval with proper error handling
            return eval(json_str)
        except Exception as e:
            print(f"Error parsing JSON data: {e}")
            return {}
    except Exception as e:
        print(f"Unexpected error parsing data: {e}")
        return {}

# PDF Report Generator class
class APYReport(FPDF):
    def __init__(self):
        super().__init__()
        self.WIDTH = 210
        self.HEIGHT = 297
        
    def header(self):
        # Set up the header with logo if available
        self.set_font('Arial', 'B', 12)
        self.cell(self.WIDTH - 20, 10, 'SquareCB Performance Experiment Report', 0, 0, 'R')
        self.ln(20)
        
    def footer(self):
        # Page numbers in the footer
        self.set_y(-15)
        self.set_font('Arial', 'I', 8)
        date_str = datetime.now().strftime('%Y-%m-%d')
        self.cell(0, 10, f'Page {self.page_no()}/{self.alias_nb_pages()} - Generated on {date_str}', 0, 0, 'C')
    
    def chapter_title(self, title):
        self.set_font('Arial', 'B', 16)
        self.set_fill_color(200, 220, 255)
        self.cell(0, 10, title, 0, 1, 'L', 1)
        self.ln(5)
        
    def chapter_body(self, body):
        self.set_font('Arial', '', 12)
        self.multi_cell(0, 6, body)
        self.ln()
        
    def section_title(self, title):
        self.set_font('Arial', 'B', 14)
        self.cell(0, 8, title, 0, 1, 'L')
        self.ln(2)
    
    def subsection_title(self, title):
        self.set_font('Arial', 'B', 12)
        self.cell(0, 6, title, 0, 1, 'L')
        self.ln(2)
    
    def add_image(self, img_path, w=None):
        if os.path.exists(img_path):
            # Check if we're close to the bottom of the page - if so, add a new page
            if self.get_y() > self.HEIGHT - 100:
                self.add_page()
            
            if w is None:
                w = self.WIDTH - 40  # Default width
            
            img_size = plt.gcf().get_size_inches()
            aspect = img_size[1] / img_size[0]
            h = w * aspect
            
            # Center the image
            x = (self.WIDTH - w) / 2
            self.image(img_path, x=x, y=self.get_y(), w=w)
            
            # Make sure to move cursor down after inserting the image
            # with extra padding to prevent overlap
            self.ln(h + 15)  # Increased space after image
            
            # Ensure we're not too close to the bottom of the page for new content
            if self.get_y() > self.HEIGHT - 40:
                self.add_page()
        else:
            self.set_text_color(255, 0, 0)
            self.cell(0, 10, f"Image not found: {img_path}", 0, 1, 'C')
            self.set_text_color(0, 0, 0)
    
    def create_table(self, headers, data, col_widths=None):
        self.set_font('Arial', 'B', 10)
        
        # Set column widths
        if col_widths is None:
            col_widths = [self.WIDTH / len(headers) - 10] * len(headers)
        
        # Table headers
        for i, header in enumerate(headers):
            self.cell(col_widths[i], 10, str(header), 1, 0, 'C', 1)
        self.ln()
        
        # Table data
        self.set_font('Arial', '', 10)
        for row in data:
            for i, cell in enumerate(row):
                self.cell(col_widths[i], 8, str(cell), 1, 0, 'C')
            self.ln()
        
        self.ln(5)

# Functions to generate visualizations
def create_visualizations(df, best_config):
    """Create and save all visualizations for the report"""
    print("Generating visualizations...")
    
    # 1. APY Comparison Bar Chart (formerly CTR)
    if 'ab_final_ctr' in df.columns:
        plt.figure(figsize=(10, 6))
        labels = ['SquareCB (Contextual)', 'A/B Testing (Random)']
        values = [best_config['final_ctr'], best_config['ab_final_ctr']]
        colors = ['#3498db', '#95a5a6']  # Blue for SquareCB, Gray for A/B Testing
        
        plt.bar(labels, values, color=colors)
        plt.title('Average Player Yield (APY) Comparison', fontsize=16)
        plt.ylabel('APY (Average Reward)', fontsize=14)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        
        # Add text labels
        for i, v in enumerate(values):
            plt.text(i, v + 0.01, f"{v:.4f}", ha='center', fontweight='bold')
        
        # Add improvement annotation
        improvement = best_config['improvement_over_ab']
        plt.annotate(f"{improvement:.2f}% improvement", 
                   xy=(0, values[0]), 
                   xytext=(0.5, max(values) * 1.1),
                   arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=.2"),
                   fontsize=12, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('apy_comparison.png', dpi=300)
        plt.close()
    
    # 2. Parameter Effects on APY
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(df['learning_rate'], df['gamma'], 
                         c=df['final_ctr'], cmap='viridis', 
                         s=80, alpha=0.8)
    plt.colorbar(scatter, label='APY')
    plt.xlabel('Learning Rate', fontsize=14)
    plt.ylabel('Gamma (Exploration)', fontsize=14)
    plt.title('Effect of Learning Rate and Gamma on APY', fontsize=16)
    
    # Mark the best configuration point
    best_lr = best_config['learning_rate']
    best_gamma = best_config['gamma']
    plt.scatter([best_lr], [best_gamma], c='red', s=150, marker='*', edgecolors='white', linewidths=1.5)
    plt.annotate('Best Config', xy=(best_lr, best_gamma), xytext=(best_lr+0.2, best_gamma+2),
                arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=.2"),
                fontsize=12, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('param_effects_apy.png', dpi=300)
    plt.close()
    
    # 3. Context Coverage Analysis
    if 'context_coverage' in df.columns:
        plt.figure(figsize=(10, 8))
        scatter = plt.scatter(df['gamma'], df['power_t'], 
                             c=df['context_coverage'], cmap='plasma', 
                             s=80, alpha=0.8)
        plt.colorbar(scatter, label='Context Coverage')
        plt.xlabel('Gamma (Exploration)', fontsize=14)
        plt.ylabel('Power T (Decay Exponent)', fontsize=14)
        plt.title('Effect of Gamma and Power T on Context Coverage', fontsize=16)
        
        # Mark the best configuration point
        best_gamma = best_config['gamma']
        best_power_t = best_config['power_t']
        plt.scatter([best_gamma], [best_power_t], c='red', s=150, marker='*', edgecolors='white', linewidths=1.5)
        
        plt.tight_layout()
        plt.savefig('context_coverage.png', dpi=300)
        plt.close()
    
    # 4. Regret Analysis
    if 'average_regret' in df.columns:
        plt.figure(figsize=(10, 8))
        scatter = plt.scatter(df['learning_rate'], df['initial_t'], 
                             c=df['average_regret'], cmap='coolwarm_r', 
                             s=80, alpha=0.8)
        plt.colorbar(scatter, label='Average Regret (Lower is Better)')
        plt.xlabel('Learning Rate', fontsize=14)
        plt.ylabel('Initial T', fontsize=14)
        plt.title('Effect of Learning Rate and Initial T on Average Regret', fontsize=16)
        
        # Mark the best configuration point
        best_lr = best_config['learning_rate']
        best_initial_t = best_config['initial_t']
        plt.scatter([best_lr], [best_initial_t], c='green', s=150, marker='*', edgecolors='white', linewidths=1.5)
        
        plt.tight_layout()
        plt.savefig('regret_analysis.png', dpi=300)
        plt.close()
    
    # 5. Context Performance Comparison
    try:
        # Only create if we have the necessary context performance data
        if 'context_performance_details' in df.columns and 'ab_context_performance' in df.columns:
            # Parse performance data
            context_perf = safe_parse_json(best_config['context_performance_details'])
            ab_perf_data = safe_parse_json(best_config['ab_context_performance'])
            
            if context_perf and ab_perf_data and 'ab_context_performance' in ab_perf_data:
                ab_perf = ab_perf_data['ab_context_performance']
                contexts = sorted(context_perf.keys())
                contexts_for_chart = [ctx for ctx in contexts if ctx in ab_perf]
                
                if contexts_for_chart:
                    plt.figure(figsize=(14, 8))
                    x = np.arange(len(contexts_for_chart))
                    width = 0.35
                    
                    cb_vals = [context_perf[ctx].get('avg_reward', 0.0) for ctx in contexts_for_chart]
                    ab_vals = [-ab_perf[ctx].get('ab_cost', 0.0) for ctx in contexts_for_chart]
                    
                    fig, ax = plt.subplots(figsize=(14, 8))
                    rects1 = ax.bar(x - width/2, cb_vals, width, label='SquareCB', color='#3498db')
                    rects2 = ax.bar(x + width/2, ab_vals, width, label='A/B Testing', color='#95a5a6')
                    
                    ax.set_ylabel('Average Reward', fontsize=14)
                    ax.set_title('SquareCB vs A/B Testing Performance by Context', fontsize=16)
                    ax.set_xticks(x)
                    ax.set_xticklabels(contexts_for_chart, rotation=45, ha='right')
                    ax.legend(fontsize=12)
                    
                    # Add improvement labels
                    for i, (cb, ab) in enumerate(zip(cb_vals, ab_vals)):
                        imp = ((cb - ab) / abs(ab)) * 100 if ab != 0 else 0
                        color = 'green' if imp > 0 else 'red'
                        ax.annotate(f"{imp:.1f}%", 
                                  xy=(i, max(cb, ab) + 0.5),
                                  ha='center', va='bottom',
                                  color=color,
                                  weight='bold')
                    
                    fig.tight_layout()
                    plt.savefig('context_performance_comparison.png', dpi=300)
                    plt.close()
    except Exception as e:
        print(f"Error creating context performance chart: {e}")
        traceback.print_exc()
    
    print("Visualizations complete.")

# Function to create the report
def generate_report():
    """Generate a comprehensive PDF report of the experiment"""
    print(f"Generating report: {OUTPUT_PDF}")
    
    # Load experimental data
    df = load_experiment_data()
    if df is None:
        return
    
    # Find best configuration
    if 'context_aware_score' in df.columns:
        best_config = df.loc[df['context_aware_score'].idxmax()].to_dict()
        metric_name = 'context-aware score'
    else:
        best_config = df.loc[df['final_ctr'].idxmax()].to_dict()
        metric_name = 'APY'
    
    # Generate visualizations
    create_visualizations(df, best_config)
    
    # Create PDF report
    pdf = APYReport()
    pdf.add_page()
    
    # Title Page
    pdf.set_font('Arial', 'B', 24)
    pdf.cell(0, 20, 'SquareCB Experiment Report', 0, 1, 'C')
    pdf.set_font('Arial', 'I', 14)
    pdf.cell(0, 10, 'Context-Aware Exploration vs A/B Testing', 0, 1, 'C')
    pdf.set_font('Arial', '', 12)
    pdf.cell(0, 10, f'Generated on: {datetime.now().strftime("%Y-%m-%d")}', 0, 1, 'C')
    pdf.ln(40)
    
    # Executive Summary
    pdf.chapter_title('Executive Summary')
    summary = (
        "This report presents the findings of our experiment comparing the SquareCB contextual " 
        "bandit algorithm with traditional A/B testing in a personalized casino game recommendation " 
        "scenario. Our results show that the contextual approach delivers significantly better performance, "
        f"with an {best_config['improvement_over_ab']:.2f}% improvement in Average Player Yield (APY) over the "
        "baseline A/B testing approach.\n\n"
        
        "The SquareCB algorithm effectively adapts to different user contexts (combinations of user "
        f"types and times of day), achieving {best_config['context_coverage']*100:.1f}% context coverage. "
        "This means the algorithm delivers consistent performance across most context combinations, "
        "providing a more personalized experience for users in different segments and at different "
        "times of day."
    )
    pdf.chapter_body(summary)
    
    # Add APY comparison chart
    if os.path.exists('apy_comparison.png'):
        pdf.add_image('apy_comparison.png', 160)
    
    # Introduction
    pdf.add_page()
    pdf.chapter_title('1. Introduction')
    intro_text = (
        "Online casino platforms face the challenge of recommending the most engaging game types "
        "to users in a highly diverse ecosystem. Different user segments (high rollers, casual players, "
        "sports enthusiasts, and new users) exhibit varied preferences that also change throughout the day. "
        "The ability to personalize recommendations based on these contexts is crucial for maximizing "
        "player engagement and revenue.\n\n"
        
        "This experiment compares two approaches to game recommendation personalization:\n\n"
        "1. Traditional A/B Testing: Randomly selecting game recommendations without considering context\n"
        "2. SquareCB Contextual Bandit: An advanced algorithm that learns optimal recommendations for each "
        "user type and time of day combination\n\n"
        
        "Our primary metric is Average Player Yield (APY), which measures the average reward (player engagement) "
        "achieved with each approach. We also analyze context-specific performance, time sensitivity, and "
        "regret metrics."
    )
    pdf.chapter_body(intro_text)
    
    # Add SquareCB explanation
    pdf.subsection_title('1.1 About SquareCB in Vowpal Wabbit')
    squarecb_explanation = (
        "SquareCB (Square Contextual Bandit) is an implementation within Vowpal Wabbit, a fast and efficient "
        "open-source machine learning library originally developed at Microsoft Research. Vowpal Wabbit is "
        "specifically optimized for online learning and provides several powerful contextual bandit algorithms.\n\n"
        
        "SquareCB offers several advantages for game recommendation systems:\n\n"
        
        "* Contextual awareness: Unlike traditional recommendation systems, SquareCB incorporates context "
        "information (user type and time of day) to make more personalized recommendations.\n\n"
        
        "* Efficient exploration: The algorithm uses a square root exploration policy that balances trying new "
        "options (exploration) with leveraging known high-performing options (exploitation).\n\n"
        
        "* Online learning: SquareCB learns continuously from each interaction, quickly adapting to changing "
        "preferences without requiring expensive offline retraining.\n\n"
        
        "* Theoretical guarantees: The algorithm provides mathematical guarantees on regret bounds, ensuring "
        "that performance improves over time and approaches optimal recommendations for each context.\n\n"
        
        "Vowpal Wabbit's implementation of SquareCB is particularly well-suited for production environments "
        "due to its low computational overhead, ability to handle large feature spaces, and proven "
        "effectiveness in real-world applications ranging from content recommendation to ad placement "
        "and, as demonstrated in this experiment, casino game recommendations."
    )
    pdf.chapter_body(squarecb_explanation)
    
    # Experiment Design
    pdf.add_page()
    pdf.chapter_title('2. Experiment Design')
    
    # Methodology
    pdf.section_title('2.1 Methodology')
    methodology_text = (
        "We simulated a casino game recommendation system with the following components:\n\n"
        
        "* User Types: high_roller, casual_player, sports_enthusiast, newbie\n"
        "* Times of Day: morning, afternoon, evening\n"
        "* Game Types (Actions): slots_heavy, live_casino, sports_betting, mixed_games, promotional\n\n"
        
        "Each user type has different baseline preferences for game types, and these preferences vary "
        "by time of day. For example, high rollers prefer live casino games, especially in the evening, "
        "while sports enthusiasts strongly prefer sports betting, particularly in the afternoon and evening.\n\n"
        
        "We conducted a hyperparameter search for the SquareCB algorithm to find optimal settings. For each "
        "parameter combination, we ran simulations with both SquareCB and A/B testing approaches using "
        f"identical contexts over {5000:,} iterations."
    )
    pdf.chapter_body(methodology_text)
    
    # Reward Structure
    pdf.section_title('2.2 Reward Structure')
    reward_text = (
        "The reward structure the bandit algorithm must learn is based on user type preferences that "
        "vary by time of day:\n\n"
    )
    pdf.chapter_body(reward_text)
    
    # Create reward structure table
    pdf.set_fill_color(240, 240, 240)
    headers = ['User Type', 'Preferred Game', 'Best Time of Day', 'Reward Range']
    data = [
        ['High Roller', 'Live Casino', 'Evening', '200-260'],
        ['Casual Player', 'Slots Heavy', 'Evening', '30-36'],
        ['Sports Enthusiast', 'Sports Betting', 'Afternoon/Evening', '100-130'],
        ['Newbie', 'Promotional', 'Evening', '30-42']
    ]
    col_widths = [40, 40, 40, 40]
    pdf.create_table(headers, data, col_widths)
    
    time_multiplier_text = (
        "Each user type's preferences are modified by time of day multipliers that enhance or reduce "
        "the expected rewards. For example, high rollers have a 1.5x multiplier in the evening, while "
        "only 0.9x in the morning.\n\n"
        
        "The algorithm must learn these complex patterns to maximize player engagement. The challenge is "
        "substantial because:\n\n"
        "* The optimal action varies across 12 different contexts (4 user types Ã— 3 times of day)\n"
        "* Rewards include random noise, making patterns harder to detect\n"
        "* The algorithm must balance exploration (trying different options) with exploitation (selecting known good options)"
    )
    pdf.chapter_body(time_multiplier_text)
    
    # Hyperparameter Search
    pdf.section_title('2.3 Hyperparameter Search')
    hyperparam_text = (
        "We conducted a grid search over the following hyperparameters for the SquareCB algorithm to find the optimal configuration for casino game recommendations:\n\n"
        
        f"* Gamma (exploration parameter): {', '.join(map(str, [5.0, 15.0, 30.0, 40.0, 50.0]))}\n"
        f"* Learning Rate: {', '.join(map(str, [0.1, 0.5, 1.0, 1.5, 2.0]))}\n"
        f"* Initial T: {', '.join(map(str, [0.5, 1.0, 3.0, 5.0, 8.0]))}\n"
        f"* Power T: {', '.join(map(str, [0.1, 0.3, 0.5, 0.7, 0.9]))}\n\n"
        
        f"This resulted in {5*5*5*5:,} parameter combinations, with each combination evaluated over "
        f"{5000:,} iterations for both SquareCB and A/B testing approaches."
    )
    pdf.chapter_body(hyperparam_text)
    
    # Add detailed explanations of hyperparameters
    pdf.subsection_title('2.3.1 Hyperparameter Definitions in Context')
    hyperparameter_details = (
        "Understanding these hyperparameters is crucial for optimizing the contextual bandit algorithm's performance in a casino game recommendation scenario:\n\n"
        
        "* Gamma (Exploration Parameter): Controls how much the algorithm explores different game recommendations "
        "versus exploiting known high-performing options. Higher values (e.g., 50.0) encourage more exploration, "
        "which is beneficial for discovering optimal recommendations across diverse user contexts but may reduce "
        "short-term performance. Lower values (e.g., 5.0) focus more on exploiting known good options, potentially "
        "maximizing immediate rewards but risking missing better options for some contexts.\n\n"
        
        "* Learning Rate: Determines how quickly the algorithm incorporates new information about game performance. "
        "Higher learning rates (e.g., 2.0) allow the system to adapt more quickly to player preferences but may cause "
        "overreaction to random fluctuations. Lower rates (e.g., 0.1) provide more stable learning but may be slower "
        "to adapt to genuine changes in player behavior or time-of-day effects.\n\n"
        
        "* Initial T: Sets the initial exploration temperature, influencing how random the recommendations are at the "
        "start of the learning process. Higher values (e.g., 8.0) result in more uniform random exploration early on, "
        "while lower values (e.g., 0.5) begin with more focused recommendations based on prior assumptions. In the casino "
        "context, this affects how quickly the system starts tailoring recommendations to different user segments.\n\n"
        
        "* Power T: Controls the decay rate of exploration over time. Higher values (e.g., 0.9) maintain exploration "
        "longer, which helps adapt to changing player preferences throughout the day. Lower values (e.g., 0.1) reduce "
        "exploration more quickly, converging faster on perceived optimal strategies for each context. This is particularly "
        "important for capturing time-of-day effects in player behavior.\n\n"
        
        "The interaction between these parameters determines how effectively the algorithm balances exploration versus "
        "exploitation across different contexts. For example, high-roller users in the evening may require different "
        "exploration strategies than casual players in the morning due to variations in reward structures and player behavior."
    )
    pdf.chapter_body(hyperparameter_details)
    
    # Evaluation Metrics
    pdf.section_title('2.4 Evaluation Metrics')
    metrics_text = (
        "We measured performance using these key metrics:\n\n"
        
        "* Average Player Yield (APY): The primary performance metric, measuring average reward per interaction\n"
        "* Improvement over A/B Testing: Percentage improvement in APY compared to random selection\n"
        "* Time Sensitivity: How differently the model behaves across time periods for the same user type\n"
        "* Context Coverage: Percentage of contexts where the algorithm performs consistently well\n"
        "* Average Regret: Average difference between obtained rewards and optimal rewards\n"
        "* Context-Specific Accuracy: How often the algorithm selects the optimal action for each context"
    )
    pdf.chapter_body(metrics_text)
    
    # Results
    pdf.add_page()
    pdf.chapter_title('3. Results')
    
    # Overall Performance
    pdf.section_title('3.1 Overall Performance')
    overall_text = (
        f"The best performing SquareCB configuration achieved an APY of {best_config['final_ctr']:.4f}, "
        f"compared to {best_config['ab_final_ctr']:.4f} for A/B testing, representing a "
        f"{best_config['improvement_over_ab']:.2f}% improvement. This demonstrates the significant "
        "advantage of context-aware recommendations over randomized testing.\n\n"
        
        "The optimal hyperparameter configuration was:\n"
        f"* Gamma: {best_config['gamma']:.2f}\n"
        f"* Learning Rate: {best_config['learning_rate']:.2f}\n"
        f"* Initial T: {best_config['initial_t']:.2f}\n"
        f"* Power T: {best_config['power_t']:.2f}"
    )
    pdf.chapter_body(overall_text)
    
    # Add interpretation of optimal parameters
    pdf.subsection_title('3.1.1 Interpretation of Optimal Parameters')
    param_interpretation = (
        "The optimal hyperparameter configuration reveals important insights about effective recommendation strategies "
        "in the casino game context:\n\n"
        
        f"* Gamma ({best_config['gamma']:.2f}): This moderately high exploration parameter indicates that "
        "balancing exploration with exploitation is crucial in this environment. The algorithm needs to "
        "explore sufficiently to discover optimal actions for each context, while not over-exploring and "
        "sacrificing too much immediate performance. This value allows the algorithm to explore enough to "
        "learn context-specific preferences while still capitalizing on known high-performing options.\n\n"
        
        f"* Learning Rate ({best_config['learning_rate']:.2f}): This learning rate represents a balance between "
        "quickly adapting to new information and maintaining stability. In the casino context, player preferences "
        "vary substantially across segments and time periods, requiring sufficient adaptability, but random "
        "fluctuations in rewards also necessitate some level of stability in the learning process.\n\n"
        
        f"* Initial T ({best_config['initial_t']:.2f}): The optimal initial temperature suggests that a moderate "
        "level of initial randomness is beneficial. This allows the algorithm to quickly explore the action space "
        "early on without being completely random, providing a good starting point for learning context-specific "
        "patterns in player preferences.\n\n"
        
        f"* Power T ({best_config['power_t']:.2f}): This decay rate controls how quickly exploration diminishes. "
        "The optimal value indicates that maintaining some level of exploration throughout the learning process "
        "is important in this domain, likely due to the variations in player behavior across different times of day "
        "and the need to continually adapt to these patterns.\n\n"
        
        "These parameter values work together to create an algorithm that effectively balances immediate reward "
        "maximization with long-term learning across diverse user contexts, resulting in significantly higher "
        "Average Player Yield compared to non-contextual approaches."
    )
    pdf.chapter_body(param_interpretation)
    
    # Add parameter effects visualization
    if os.path.exists('param_effects_apy.png'):
        # Ensure we start on a new page for this visualization
        if pdf.get_y() > pdf.HEIGHT - 180:  # Need enough space for image and caption
            pdf.add_page()
        pdf.add_image('param_effects_apy.png', 160)
        
        performance_notes = (
            "The visualization above shows how learning rate and gamma (exploration parameter) affect APY. "
            "The optimal configuration (marked with a star) balances exploration and exploitation to achieve "
            "the highest rewards."
        )
        pdf.chapter_body(performance_notes)
    
    # Context Coverage and Time Sensitivity
    pdf.add_page()  # Always start this section on a new page
    pdf.section_title('3.2 Context Coverage and Time Sensitivity')
    context_text = (
        f"The SquareCB algorithm achieved a context coverage of {best_config['context_coverage']*100:.1f}%, "
        "indicating that it performs consistently well across most context combinations. "
        f"The time sensitivity score of {best_config['time_sensitivity']:.4f} shows that the algorithm "
        "effectively adapts its recommendations based on the time of day.\n\n"
        
        f"The algorithm had the highest regret for the '{best_config['worst_context']}' context, "
        "suggesting this particular combination was the most challenging to optimize."
    )
    pdf.chapter_body(context_text)
    
    # Add context coverage visualization
    if os.path.exists('context_coverage.png'):
        pdf.add_image('context_coverage.png', 160)
        
    # Add regret analysis visualization
    if os.path.exists('regret_analysis.png'):
        # Ensure we have a page break if needed
        if pdf.get_y() > pdf.HEIGHT - 180:
            pdf.add_page()
        pdf.add_image('regret_analysis.png', 160)
    
    # Context-Specific Performance
    pdf.add_page()
    pdf.section_title('3.3 Context-Specific Performance')
    
    # Parse context performance details
    total_accuracy = 0
    context_data_rows = []
    
    try:
        context_perf = safe_parse_json(best_config['context_performance_details'])
        if context_perf:
            num_contexts = len(context_perf)
            
            for context, metrics in sorted(context_perf.items()):
                try:
                    optimal_action = metrics.get('optimal_action', 'unknown')
                    avg_reward = metrics.get('avg_reward', 0.0)
                    optimal_reward = metrics.get('optimal_reward', 0.0)
                    accuracy = metrics.get('accuracy', 0.0)
                    regret = metrics.get('regret', 0.0)
                    
                    accuracy_pct = accuracy * 100
                    total_accuracy += accuracy
                    
                    context_data_rows.append([
                        context, 
                        optimal_action, 
                        f"{avg_reward:.2f}", 
                        f"{optimal_reward:.2f}", 
                        f"{accuracy_pct:.1f}%", 
                        f"{regret:.2f}"
                    ])
                except Exception as e:
                    print(f"Error processing metrics for {context}: {e}")
            
            avg_accuracy = (total_accuracy/num_contexts)*100 if num_contexts else 0
            context_specific_text = (
                "The table below shows how SquareCB performed across different user type and time of day combinations. "
                f"The algorithm achieved an average accuracy of {avg_accuracy:.2f}% in selecting the optimal action "
                "across all contexts.\n\n"
                
                "Key observations:\n"
                "* The algorithm learned the optimal action for most contexts\n"
                "* Performance varied by context, with some combinations being harder to optimize\n"
                "* The average reward is consistently close to the optimal reward in most contexts"
            )
            pdf.chapter_body(context_specific_text)
            
            # Create context performance table
            headers = ['Context', 'Optimal Action', 'Avg Reward', 'Optimal Reward', 'Accuracy', 'Regret']
            col_widths = [40, 35, 25, 30, 25, 25]
            pdf.create_table(headers, context_data_rows, col_widths)
        else:
            pdf.chapter_body("No context-specific performance data available.")
    except Exception as e:
        pdf.chapter_body(f"Could not analyze context performance data: {str(e)}")
    
    # A/B Testing Comparison
    pdf.add_page()
    pdf.section_title('3.4 SquareCB vs A/B Testing Comparison')
    
    ab_comparison_text = (
        "The following comparison shows how SquareCB outperforms A/B testing across different contexts. "
        "The contextual approach consistently delivers higher rewards by learning the optimal actions "
        "for each user type and time of day combination."
    )
    pdf.chapter_body(ab_comparison_text)
    
    # Add context performance comparison chart
    if os.path.exists('context_performance_comparison.png'):
        # Start on a new page for this large visualization
        pdf.add_page()
        pdf.add_image('context_performance_comparison.png', 180)
        
        ab_insight_text = (
            "The chart above compares SquareCB and A/B testing performance across contexts, with "
            "percentage improvements labeled. Note that the improvement varies by context, with "
            "some showing particularly dramatic gains. This illustrates the value of context-aware "
            "recommendations over random selection, especially for contexts with strong preferences."
        )
        pdf.chapter_body(ab_insight_text)
    
    # Parse A/B comparison data
    ab_data_rows = []
    try:
        context_perf = safe_parse_json(best_config['context_performance_details'])
        ab_perf_data = safe_parse_json(best_config['ab_context_performance'])
        
        if context_perf and ab_perf_data and 'ab_context_performance' in ab_perf_data:
            ab_perf = ab_perf_data['ab_context_performance']
            cb_rewards = []
            ab_rewards = []
            
            for context in sorted(context_perf.keys()):
                if context in ab_perf:
                    try:
                        cb_reward = context_perf[context].get('avg_reward', 0.0)
                        ab_metrics = ab_perf[context]
                        if isinstance(ab_metrics, dict):
                            ab_cost = ab_metrics.get('ab_cost', 0.0)
                        else:
                            ab_cost = 0.0
                        
                        ab_reward = -ab_cost  # Reward is negative cost
                        improvement = ((cb_reward - ab_reward) / abs(ab_reward)) * 100 if ab_reward != 0 else 0
                        
                        cb_rewards.append(cb_reward)
                        ab_rewards.append(ab_reward)
                        
                        ab_data_rows.append([
                            context, 
                            f"{cb_reward:.2f}", 
                            f"{ab_reward:.2f}", 
                            f"{improvement:.2f}%"
                        ])
                    except Exception as e:
                        print(f"Error processing A/B comparison for {context}: {e}")
            
            # Add averages row if we have data
            if cb_rewards and ab_rewards:
                avg_cb = sum(cb_rewards) / len(cb_rewards) 
                avg_ab = sum(ab_rewards) / len(ab_rewards)
                avg_imp = ((avg_cb - avg_ab) / abs(avg_ab)) * 100 if avg_ab != 0 else 0
                
                ab_data_rows.append([
                    "AVERAGE", 
                    f"{avg_cb:.2f}", 
                    f"{avg_ab:.2f}", 
                    f"{avg_imp:.2f}%"
                ])
            
            # Create comparison table
            headers = ['Context', 'SquareCB Reward', 'A/B Testing Reward', 'Improvement']
            col_widths = [45, 40, 40, 35]
            pdf.create_table(headers, ab_data_rows, col_widths)
        else:
            pdf.chapter_body("No A/B testing comparison data available.")
    except Exception as e:
        pdf.chapter_body(f"Could not analyze A/B comparison data: {str(e)}")
    
    # Conclusion
    pdf.add_page()
    pdf.chapter_title('4. Conclusion')
    conclusion_text = (
        "This experiment demonstrates the significant advantages of context-aware recommendation "
        "systems using SquareCB over traditional A/B testing approaches in a casino game recommendation "
        "scenario. Key findings include:\n\n"
        
        f"1. Overall Performance: SquareCB achieved a {best_config['improvement_over_ab']:.2f}% improvement "
        "in Average Player Yield (APY) compared to A/B testing, demonstrating the substantial value "
        "of contextual awareness.\n\n"
        
        f"2. Context Coverage: The algorithm successfully learned optimal strategies for {best_config['context_coverage']*100:.1f}% "
        "of contexts, showing its ability to adapt to different user types and times of day.\n\n"
        
        "3. Personalization: SquareCB effectively personalized recommendations based on both user type "
        "and time of day, achieving high accuracy in selecting optimal actions across contexts.\n\n"
        
        "4. Consistent Improvement: The contextual approach outperformed A/B testing across all "
        "contexts, with particularly significant improvements for contexts with strong preferences.\n\n"
        
        "These results highlight the importance of considering context in recommendation systems. "
        "By accounting for user type and time of day, SquareCB can deliver more personalized and "
        "engaging recommendations, leading to higher rewards and better user experiences.\n\n"
        
        "The optimal hyperparameter configuration balances exploration and exploitation, allowing "
        "the algorithm to quickly learn context patterns while continuing to explore alternatives. "
        "This approach is particularly valuable in dynamic environments where user preferences may "
        "change over time."
    )
    pdf.chapter_body(conclusion_text)
    
    # Business Implications
    pdf.section_title('4.1 Business Implications')
    business_text = (
        "The findings of this experiment have several important implications for online casino platforms:\n\n"
        
        "* Revenue Potential: The significant improvement in player engagement (APY) suggests substantial "
        "revenue uplift potential from implementing contextual recommendations.\n\n"
        
        "* Personalization Strategy: The results validate the importance of considering both user segments "
        "and time of day in personalization strategies.\n\n"
        
        "* Resource Allocation: Different contexts show varying levels of improvement, suggesting where "
        "personalization efforts should be focused for maximum impact.\n\n"
        
        "* Technical Implementation: The optimal hyperparameter configuration provides a starting point "
        "for implementing SquareCB in production systems."
    )
    pdf.chapter_body(business_text)
    
    # Future Work
    pdf.section_title('4.2 Future Work')
    future_text = (
        "Several directions for future work could further enhance the value of contextual recommendations:\n\n"
        
        "* Additional Contexts: Incorporate additional contextual factors such as device type, player history, "
        "or geographic location.\n\n"
        
        "* Dynamic Adaptation: Explore approaches that can adapt to changing user preferences over time.\n\n"
        
        "* Multi-Armed Contextual Bandits: Extend to scenarios with more complex action spaces, such as "
        "recommending specific games rather than game categories.\n\n"
        
        "* Real-World Validation: Conduct A/B tests in real-world environments to validate the simulation "
        "findings with actual player behavior."
    )
    pdf.chapter_body(future_text)
    
    # Save the PDF
    pdf.output(OUTPUT_PDF)
    print(f"Report generated successfully: {OUTPUT_PDF}")

if __name__ == "__main__":
    generate_report() 